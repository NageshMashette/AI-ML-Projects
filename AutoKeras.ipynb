{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autokeras\n",
      "  Using cached autokeras-1.0.12-py3-none-any.whl (164 kB)\n",
      "Requirement already satisfied: packaging in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from autokeras) (20.8)\n",
      "Requirement already satisfied: scikit-learn in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from autokeras) (0.24.0)\n",
      "Requirement already satisfied: tensorflow>=2.3.0 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from autokeras) (2.4.0)\n",
      "Requirement already satisfied: pandas in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from autokeras) (1.2.0)\n",
      "Collecting keras-tuner>=1.0.2\n",
      "  Using cached keras_tuner-1.0.2-py3-none-any.whl\n",
      "Requirement already satisfied: requests in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from keras-tuner>=1.0.2->autokeras) (2.25.1)\n",
      "Requirement already satisfied: scipy in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from keras-tuner>=1.0.2->autokeras) (1.5.2)\n",
      "Requirement already satisfied: numpy in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from keras-tuner>=1.0.2->autokeras) (1.19.2)\n",
      "Requirement already satisfied: tqdm in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from keras-tuner>=1.0.2->autokeras) (4.56.0)\n",
      "Requirement already satisfied: future in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from keras-tuner>=1.0.2->autokeras) (0.18.2)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from tensorflow>=2.3.0->autokeras) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from tensorflow>=2.3.0->autokeras) (1.1.2)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from tensorflow>=2.3.0->autokeras) (0.36.2)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from tensorflow>=2.3.0->autokeras) (2.4.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from tensorflow>=2.3.0->autokeras) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from tensorflow>=2.3.0->autokeras) (3.3.0)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from tensorflow>=2.3.0->autokeras) (0.3.3)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from tensorflow>=2.3.0->autokeras) (1.32.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from tensorflow>=2.3.0->autokeras) (2.4.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from tensorflow>=2.3.0->autokeras) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from tensorflow>=2.3.0->autokeras) (3.7.4.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from tensorflow>=2.3.0->autokeras) (3.13.0)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from tensorflow>=2.3.0->autokeras) (2.10.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from tensorflow>=2.3.0->autokeras) (0.11.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from tensorflow>=2.3.0->autokeras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from tensorflow>=2.3.0->autokeras) (1.12)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from tensorflow>=2.3.0->autokeras) (1.12.1)\n",
      "Requirement already satisfied: setuptools in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from protobuf>=3.9.2->tensorflow>=2.3.0->autokeras) (51.3.3.post20210118)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.3.3)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.24.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (0.4.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.6.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (4.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (4.7)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from requests->keras-tuner>=1.0.2->autokeras) (1.26.2)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from requests->keras-tuner>=1.0.2->autokeras) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from requests->keras-tuner>=1.0.2->autokeras) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from requests->keras-tuner>=1.0.2->autokeras) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.3.0->autokeras) (3.1.0)\n",
      "Collecting colorama\n",
      "  Using cached colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from packaging->autokeras) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from pandas->autokeras) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from pandas->autokeras) (2020.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from scikit-learn->autokeras) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/baatutech/anaconda3/envs/tensor/lib/python3.8/site-packages (from scikit-learn->autokeras) (1.0.0)\n",
      "Collecting tabulate\n",
      "  Using cached tabulate-0.8.7-py3-none-any.whl (24 kB)\n",
      "Collecting terminaltables\n",
      "  Using cached terminaltables-3.1.0-py3-none-any.whl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: terminaltables, tabulate, colorama, keras-tuner, autokeras\n",
      "Successfully installed autokeras-1.0.12 colorama-0.4.4 keras-tuner-1.0.2 tabulate-0.8.7 terminaltables-3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install autokeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 10s 1us/step\n",
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "[5 0 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import autokeras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.python.keras.utils.data_utils import Sequence\n",
    "import autokeras as ak\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape)  # (60000, 28, 28)\n",
    "print(y_train.shape)  # (60000,)\n",
    "print(y_train[:3])  # array([7, 2, 1], dtype=uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 00m 53s]\n",
      "val_loss: 0.038733888417482376\n",
      "\n",
      "Best val_loss So Far: 0.038733888417482376\n",
      "Total elapsed time: 00h 00m 53s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3007 - accuracy: 0.9064\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0816 - accuracy: 0.9747\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0614 - accuracy: 0.9811\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0525 - accuracy: 0.9837\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0487 - accuracy: 0.9843\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0424 - accuracy: 0.9868\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0402 - accuracy: 0.9874\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0364 - accuracy: 0.9888\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0311 - accuracy: 0.9900\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0304 - accuracy: 0.9898\n",
      "INFO:tensorflow:Assets written to: ./image_classifier/best_model/assets\n",
      "[['7']\n",
      " ['2']\n",
      " ['1']\n",
      " ...\n",
      " ['4']\n",
      " ['5']\n",
      " ['6']]\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0324 - accuracy: 0.9904\n",
      "[0.032407235354185104, 0.9904000163078308]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the image classifier.\n",
    "clf = ak.ImageClassifier(\n",
    "    overwrite=True,\n",
    "    max_trials=1)\n",
    "# Feed the image classifier with training data.\n",
    "clf.fit(x_train, y_train, epochs=10)\n",
    "\n",
    "\n",
    "# Predict with the best model.\n",
    "predicted_y = clf.predict(x_test)\n",
    "print(predicted_y)\n",
    "\n",
    "\n",
    "# Evaluate the best model with testing data.\n",
    "print(clf.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) /tmp/pip-req-build-jhawztrk/opencv/modules/highgui/src/window.cpp:645: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-a5ebdbd4c5c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;31m# Clean up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.1) /tmp/pip-req-build-jhawztrk/opencv/modules/highgui/src/window.cpp:645: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Import utilites\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "# Name of the directory containing the object detection module we're using\n",
    "MODEL_NAME = '/home/baatutech/Documents/TensorflowOD/workspace/training_demo/exported-models/my_model1/'\n",
    "VIDEO_NAME = '/home/baatutech/Downloads/Video_04.mp4'\n",
    "\n",
    "# Grab path to current working directory\n",
    "CWD_PATH = os.getcwd()\n",
    "\n",
    "# Path to frozen detection graph .pb file, which contains the model that is used\n",
    "# for object detection.\n",
    "PATH_TO_CKPT = os.path.join(CWD_PATH,MODEL_NAME,'/home/baatutech/Documents/TensorflowOD/workspace/training_demo/exported-models/my_model1/saved_model/saved_model.pb')\n",
    "\n",
    "# Path to label map file\n",
    "PATH_TO_LABELS = os.path.join(CWD_PATH,'training','/home/baatutech/Documents/TensorflowOD/workspace/training_demo/annotations/label_map.pbtxt')\n",
    "\n",
    "# Path to video\n",
    "PATH_TO_VIDEO = os.path.join(CWD_PATH,VIDEO_NAME)\n",
    "\n",
    "# Number of classes the object detector can identify\n",
    "NUM_CLASSES = 6\n",
    "\n",
    "# Load the label map.\n",
    "# Label maps map indices to category names, so that when our convolution\n",
    "# network predicts `5`, we know that this corresponds to `king`.\n",
    "# Here we use internal utility functions, but anything that returns a\n",
    "# dictionary mapping integers to appropriate string labels would be fine\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "'''\n",
    "# Load the Tensorflow model into memory.\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.compat.v1.GraphDef()\n",
    "    with tf.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = compat.as_bytes(fid.read())\n",
    "       # od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "        sess = tf.Session(graph=detection_graph)\n",
    "'''\n",
    "detection_graph = tf.compat.v1.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.compat.v1.GraphDef()\n",
    "    with tf.io.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph =compat.as_bytes(fid.read())\n",
    "        sm=saved_model_pb2.SavedModel()\n",
    "        sm.ParseFromString(serialized_graph)\n",
    "        \n",
    "        #od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(sm.meta_graphs[0].graph_def)   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "image_tensor = 'image_tensor:0'\n",
    "boxes = 'detection_boxes:0'\n",
    "scores = 'detection_scores:0'\n",
    "classes = 'detection_classes:0'\n",
    "num_detections = 'num_detections:0'\n",
    "\n",
    "'''\n",
    "output_dict = sess.run([boxes, scores, classes, num_detections],\n",
    "                feed_dict={image_tensor: np.expand_dims(img, 0)})\n",
    "\n",
    "# Define input and output tensors (i.e. data) for the object detection classifier\n",
    "#image_tensor = 'image_tensor:0'\n",
    "# Input tensor is the image\n",
    "image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "# Output tensors are the detection boxes, scores, and classes\n",
    "# Each box represents a part of the image where a particular object was detected\n",
    "detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "\n",
    "# Each score represents level of confidence for each of the objects.\n",
    "# The score is shown on the result image, together with the class label.\n",
    "detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "\n",
    "# Number of objects detected\n",
    "num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "'''\n",
    "# Open video file\n",
    "video = cv2.VideoCapture(PATH_TO_VIDEO)\n",
    "\n",
    "while(video.isOpened()):\n",
    "\n",
    "    # Acquire frame and expand frame dimensions to have shape: [1, None, None, 3]\n",
    "    # i.e. a single-column array, where each item in the column has the pixel RGB value\n",
    "    ret, frame = video.read()\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_expanded = np.expand_dims(frame_rgb, axis=0)\n",
    "\n",
    "    # Perform the actual detection by running the model with the image as input\n",
    "    (boxes, scores, classes, num) = sess.run(\n",
    "        [boxes, scores, classes, num_detections],\n",
    "        feed_dict={image_tensor: frame_expanded})\n",
    "\n",
    "    # Draw the results of the detection (aka 'visulaize the results')\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        frame,\n",
    "        np.squeeze(boxes),\n",
    "        np.squeeze(classes).astype(np.int32),\n",
    "        np.squeeze(scores),\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8,\n",
    "        min_score_thresh=0.60)\n",
    "\n",
    "    # All the results have been drawn on the frame, so it's time to display it.\n",
    "    cv2.imshow('Object detector', frame)\n",
    "\n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "# Clean up\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "videoFile = \"/home/baatutech/Downloads/Video_04.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(videoFile)\n",
    "frameRate = cap.get(5) #frame rate\n",
    "x=1\n",
    "while(cap.isOpened()):\n",
    "    frameId = cap.get(1) #current frame number\n",
    "    ret, frame = cap.read()\n",
    "    if (ret != True):\n",
    "        break\n",
    "    if (frameId % math.floor(frameRate) == 0):\n",
    "        filename = '/home/baatutech/Downloads/image' +  str(int(x)) + \".jpg\";x+=1\n",
    "        cv2.imwrite(filename, frame)\n",
    "\n",
    "cap.release()\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import numpy as np\n",
    "img_path = '/home/baatutech/Desktop/test/8.jpg'\n",
    "img = image.load_img(img_path, target_size=(28, 28))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[151.061   138.22101 131.32   ]\n",
      "   [151.061   138.22101 131.32   ]\n",
      "   [151.061   138.22101 131.32   ]\n",
      "   ...\n",
      "   [151.061   138.22101 131.32   ]\n",
      "   [151.061   138.22101 131.32   ]\n",
      "   [151.061   138.22101 131.32   ]]\n",
      "\n",
      "  [[151.061   138.22101 131.32   ]\n",
      "   [151.061   138.22101 131.32   ]\n",
      "   [151.061   138.22101 131.32   ]\n",
      "   ...\n",
      "   [151.061   138.22101 131.32   ]\n",
      "   [151.061   138.22101 131.32   ]\n",
      "   [151.061   138.22101 131.32   ]]\n",
      "\n",
      "  [[151.061   138.22101 131.32   ]\n",
      "   [151.061   138.22101 131.32   ]\n",
      "   [151.061   138.22101 131.32   ]\n",
      "   ...\n",
      "   [151.061   138.22101 131.32   ]\n",
      "   [151.061   138.22101 131.32   ]\n",
      "   [151.061   138.22101 131.32   ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[151.061   138.22101 131.32   ]\n",
      "   [151.061   138.22101 131.32   ]\n",
      "   [151.061   138.22101 131.32   ]\n",
      "   ...\n",
      "   [151.061   138.22101 131.32   ]\n",
      "   [151.061   138.22101 131.32   ]\n",
      "   [151.061   138.22101 131.32   ]]\n",
      "\n",
      "  [[151.061   138.22101 131.32   ]\n",
      "   [151.061   138.22101 131.32   ]\n",
      "   [151.061   138.22101 131.32   ]\n",
      "   ...\n",
      "   [151.061   138.22101 131.32   ]\n",
      "   [151.061   138.22101 131.32   ]\n",
      "   [151.061   138.22101 131.32   ]]\n",
      "\n",
      "  [[151.061   138.22101 131.32   ]\n",
      "   [151.061   138.22101 131.32   ]\n",
      "   [151.061   138.22101 131.32   ]\n",
      "   ...\n",
      "   [151.061   138.22101 131.32   ]\n",
      "   [151.061   138.22101 131.32   ]\n",
      "   [151.061   138.22101 131.32   ]]]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (1, 28, 28, 3) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8c4e50a7614d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensor/lib/python3.8/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mmatshow\u001b[0;34m(A, fignum, **kwargs)\u001b[0m\n\u001b[1;32m   2299\u001b[0m         \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfigaspect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2300\u001b[0m         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.09\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.775\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.775\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2301\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2302\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mmatshow\u001b[0;34m(self, Z, **kwargs)\u001b[0m\n\u001b[1;32m   7751\u001b[0m               \u001b[0;34m'aspect'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'equal'\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0;31m# (already the imshow default)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7752\u001b[0m               **kwargs}\n\u001b[0;32m-> 7753\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7754\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7755\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_top\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor/lib/python3.8/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1447\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor/lib/python3.8/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5521\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5523\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5524\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor/lib/python3.8/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    709\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    710\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 711\u001b[0;31m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0m\u001b[1;32m    712\u001b[0m                             .format(self._A.shape))\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (1, 28, 28, 3) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(x)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
